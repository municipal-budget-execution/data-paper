{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory \n",
    "input_path = os.environ.get('input_path')\n",
    "fig_output = os.environ.get('fig_output')\n",
    "tab_output = os.environ.get('tab_output')\n",
    "\n",
    "# Queries config\n",
    "project_id_bq = os.environ.get('project_id_bq')\n",
    "run_query = os.environ.get('run_query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uMuffdQtxmI"
   },
   "outputs": [],
   "source": [
    "# Merge commitment and verification\n",
    "# Necessary to get the percentage of unique commitments that are both in commitment (empenho) and verification (liquidacao)\n",
    "# We use it to construct the variable 'Has verification information'\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        e.sigla_uf,\n",
    "        COUNT(DISTINCT e.id_empenho_bd) as distinct_commitments,\n",
    "        COUNT(DISTINCT e.id_municipio) as number_municipalities,\n",
    "        COUNT(DISTINCT CASE WHEN SUBSTR(e.elemento_despesa, 5, 2) IN ('30', '32', '52') THEN e.id_empenho_bd END) as procurement_commitments,\n",
    "        COUNT(DISTINCT CASE WHEN l.id_empenho_bd IS NOT NULL THEN l.id_empenho_bd END) / COUNT(DISTINCT e.id_empenho_bd) as has_verification_information\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM basedosdados.world_wb_mides.empenho\n",
    "        WHERE id_empenho_bd IS NOT NULL\n",
    "    ) e\n",
    "    LEFT JOIN (\n",
    "        SELECT *\n",
    "        FROM basedosdados.world_wb_mides.liquidacao\n",
    "        WHERE id_empenho_bd IS NOT NULL\n",
    "    ) l\n",
    "    ON e.id_empenho_bd = l.id_empenho_bd\n",
    "    WHERE (e.sigla_uf <> 'RS' OR (e.sigla_uf = 'RS' AND e.ano > 2009))\n",
    "    GROUP BY e.sigla_uf\n",
    "\n",
    "    '''\n",
    "    empenho_liquidacao = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    empenho_liquidacao.to_csv(os.path.join(input_path,'empenho_liquidacao.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeFWtVKhjSpk"
   },
   "outputs": [],
   "source": [
    "# Merge commitment and payment\n",
    "# Necessary to get the percentage of unique commitments that are both in commitment (empenho) and payment (pagamento)\n",
    "# We use it to construct the variable 'Has payment information'\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        e.sigla_uf,\n",
    "        COUNT(DISTINCT CASE WHEN p.id_empenho_bd IS NOT NULL THEN p.id_empenho_bd END) / COUNT(DISTINCT e.id_empenho_bd) as has_payment_information\n",
    "    FROM (\n",
    "        SELECT *\n",
    "        FROM basedosdados.world_wb_mides.empenho\n",
    "        WHERE id_empenho_bd IS NOT NULL\n",
    "    ) e\n",
    "    LEFT JOIN (\n",
    "        SELECT *\n",
    "        FROM basedosdados.world_wb_mides.pagamento\n",
    "        WHERE id_empenho_bd IS NOT NULL\n",
    "    ) p\n",
    "    ON e.id_empenho_bd = p.id_empenho_bd\n",
    "    WHERE (e.sigla_uf <> 'RS' OR (e.sigla_uf = 'RS' AND e.ano > 2009))\n",
    "    GROUP BY e.sigla_uf\n",
    "\n",
    "    '''\n",
    "    empenho_pagamento = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    empenho_pagamento.to_csv(os.path.join(input_path,'empenho_pagamento.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6_zK3wTqfG_"
   },
   "outputs": [],
   "source": [
    "# Count commitment observations\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        sigla_uf,\n",
    "        COUNT(*) as obs_commitments,\n",
    "        SUM(CASE WHEN valor_final > 0 AND id_empenho_bd IS NOT NULL THEN 1 ELSE 0 END) as total_positive_values,\n",
    "    FROM\n",
    "      basedosdados.world_wb_mides.empenho\n",
    "    WHERE (sigla_uf <> 'RS' OR (sigla_uf = 'RS' AND ano > 2009))\n",
    "    GROUP BY sigla_uf\n",
    "\n",
    "    '''\n",
    "    empenho = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    empenho.to_csv(os.path.join(input_path,'empenho.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JymPbnH3RgR7"
   },
   "outputs": [],
   "source": [
    "# Count number of distinct verifications\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        sigla_uf,\n",
    "        COUNT(*) as obs_verifications,\n",
    "        COUNT(DISTINCT CASE WHEN id_liquidacao_bd IS NOT NULL THEN id_liquidacao_bd END) as distinct_verifications,\n",
    "    FROM\n",
    "      basedosdados.world_wb_mides.liquidacao\n",
    "    WHERE (sigla_uf <> 'RS' OR (sigla_uf = 'RS' AND ano > 2009))\n",
    "    GROUP BY sigla_uf\n",
    "\n",
    "    '''\n",
    "    liquidacao = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    liquidacao.to_csv(os.path.join(input_path,'liquidacao.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvDEvvdBlvCr"
   },
   "outputs": [],
   "source": [
    "# Count number of distinct payments and distinct sellers\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        sigla_uf,\n",
    "        COUNT(*) as obs_payments,\n",
    "        COUNT(DISTINCT CASE WHEN id_pagamento_bd IS NOT NULL THEN id_pagamento_bd END) as distinct_payments,\n",
    "        COUNT(DISTINCT CONCAT(documento_credor,nome_credor)) AS distinct_sellers,\n",
    "    FROM\n",
    "      basedosdados.world_wb_mides.pagamento\n",
    "    WHERE (sigla_uf <> 'RS' OR (sigla_uf = 'RS' AND ano > 2009))\n",
    "    GROUP BY sigla_uf\n",
    "\n",
    "    '''\n",
    "    pagamento = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    pagamento.to_csv(os.path.join(input_path,'pagamento.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71Xi-Vx0agRp"
   },
   "outputs": [],
   "source": [
    "# Count total ammount per state and year\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        ano, sigla_uf,\n",
    "        SAFE_CAST(SUM(valor_final) / 1e9 AS FLOAT64) AS total_payment_billion,\n",
    "    FROM\n",
    "      basedosdados.world_wb_mides.pagamento\n",
    "    WHERE (sigla_uf <> 'RS' OR (sigla_uf = 'RS' AND ano > 2009))\n",
    "    GROUP BY sigla_uf, ano\n",
    "\n",
    "    '''\n",
    "    total_pagamento_ano = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    total_pagamento_ano.to_csv(os.path.join(input_path,'total_pagamento_ano.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xl_l_wPLP6tz"
   },
   "outputs": [],
   "source": [
    "# query for PE\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        sigla_uf,\n",
    "        COUNT(*) as obs_commitments,\n",
    "        SUM(CASE WHEN valor_final > 0 THEN 1 ELSE 0 END) as total_positive_values,\n",
    "        COUNT(DISTINCT id_municipio) as number_municipalities,\n",
    "        COUNT(CASE WHEN SUBSTR(elemento_despesa, 5, 2) IN ('30', '32', '52') THEN id_empenho END) as procurement_commitments\n",
    "    FROM basedosdados.world_wb_mides.empenho\n",
    "    WHERE sigla_uf = 'PE'\n",
    "    GROUP BY sigla_uf\n",
    "\n",
    "    '''\n",
    "    empenho_pe = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    empenho_pe.to_csv(os.path.join(input_path,'empenho_pe.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_Sc9xGWFk6o"
   },
   "outputs": [],
   "source": [
    "# query for PE\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "\n",
    "    SELECT\n",
    "        l.sigla_uf,\n",
    "        l.obs_verifications,\n",
    "        p.obs_payments\n",
    "    FROM (\n",
    "        SELECT sigla_uf, COUNT(*) AS obs_verifications\n",
    "        FROM basedosdados.world_wb_mides.liquidacao\n",
    "        WHERE sigla_uf = 'PE'\n",
    "        GROUP BY sigla_uf\n",
    "    ) l\n",
    "    LEFT JOIN (\n",
    "        SELECT sigla_uf, COUNT(*) AS obs_payments\n",
    "        FROM basedosdados.world_wb_mides.pagamento\n",
    "        WHERE sigla_uf = 'PE'\n",
    "        GROUP BY sigla_uf\n",
    "    ) p\n",
    "    ON l.sigla_uf = p.sigla_uf\n",
    "\n",
    "    '''\n",
    "    liq_pag_pe = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    liq_pag_pe.to_csv(os.path.join(input_path,'liq_pag_pe.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPCA\n",
    "\n",
    "def run_query_and_save_results():\n",
    "\n",
    "    query = '''\n",
    "    SELECT\n",
    "        variacao_anual, ano, mes\n",
    "    FROM\n",
    "      basedosdados.br_ibge_ipca.mes_brasil\n",
    "    WHERE mes = 12 AND ano > 2000\n",
    "    ORDER BY ano\n",
    "    '''\n",
    "    ipca_anual = bd.read_sql(query, billing_project_id=project_id_bq)\n",
    "\n",
    "    ipca_anual.to_csv(os.path.join(input_path,'ipca_anual.csv'), index=False, na_rep='', float_format='%.2f')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if run_query == 'True':\n",
    "        run_query_and_save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Descriptive statistics table\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m empenho_liquidacao = pd.read_csv(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mempenho_liquidacao.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      4\u001b[39m empenho_pagamento = pd.read_csv(os.path.join(input_path,\u001b[33m'\u001b[39m\u001b[33mempenho_pagamento.csv\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      5\u001b[39m empenho = pd.read_csv(os.path.join(input_path,\u001b[33m'\u001b[39m\u001b[33mempenho.csv\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen posixpath>:76\u001b[39m, in \u001b[36mjoin\u001b[39m\u001b[34m(a, *p)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics table\n",
    "\n",
    "empenho_liquidacao = pd.read_csv(os.path.join(input_path,'empenho_liquidacao.csv'))\n",
    "empenho_pagamento = pd.read_csv(os.path.join(input_path,'empenho_pagamento.csv'))\n",
    "empenho = pd.read_csv(os.path.join(input_path,'empenho.csv'))\n",
    "liquidacao = pd.read_csv(os.path.join(input_path,'liquidacao.csv'))\n",
    "pagamento = pd.read_csv(os.path.join(input_path,'pagamento.csv'))\n",
    "total_pagamento_ano = pd.read_csv(os.path.join(input_path,'total_pagamento_ano.csv'))\n",
    "empenho_pe = pd.read_csv(os.path.join(input_path,'empenho_pe.csv'))\n",
    "liq_pag_pe = pd.read_csv(os.path.join(input_path,'liq_pag_pe.csv'))\n",
    "ipca_anual = pd.read_csv(os.path.join(input_path,'ipca_anual.csv'))\n",
    "\n",
    "# 1. Deflate payment\n",
    "\n",
    "# filter years\n",
    "total_pagamento_ano = total_pagamento_ano[total_pagamento_ano['ano']<2022]\n",
    "\n",
    "# create deflator\n",
    "\n",
    "deflatores = [ipca_anual['variacao_anual'][0]+100]\n",
    "\n",
    "for i in range(1, 21):\n",
    "   deflator = (1+(ipca_anual['variacao_anual'][i]/100))*deflatores[i -1]\n",
    "   deflatores.append(deflator)\n",
    "\n",
    "deflator_2021 = deflatores[20]\n",
    "\n",
    "deflatores = pd.DataFrame(deflatores,columns=['deflator'])\n",
    "deflatores['ano'] = ipca_anual['ano']\n",
    "\n",
    "total_pagamento_ano = pd.merge(total_pagamento_ano, deflatores, how='left', left_on='ano', right_on='ano')\n",
    "total_pagamento_ano['total_payment_billion_real'] = deflator_2021*total_pagamento_ano['total_payment_billion']/total_pagamento_ano['deflator']\n",
    "\n",
    "total_pagamento = total_pagamento_ano.groupby('sigla_uf')['total_payment_billion_real'].sum()\n",
    "\n",
    "# 2. Join all variables\n",
    "\n",
    "tabela = pd.merge(empenho_liquidacao, empenho_pagamento, how='left', left_on='sigla_uf', right_on='sigla_uf')\n",
    "tabela = pd.merge(tabela, empenho, how='left', left_on='sigla_uf', right_on='sigla_uf')\n",
    "tabela = pd.merge(tabela, pagamento, how='left', left_on='sigla_uf', right_on='sigla_uf')\n",
    "tabela = pd.merge(tabela, liquidacao, how='left', left_on='sigla_uf', right_on='sigla_uf')\n",
    "\n",
    "stats_pe = pd.merge(empenho_pe, liq_pag_pe, how='left', left_on = 'sigla_uf', right_on = 'sigla_uf')\n",
    "tabela = pd.concat([tabela,stats_pe],axis=0)\n",
    "\n",
    "tabela = pd.merge(tabela, total_pagamento, how='left', left_on='sigla_uf', right_on='sigla_uf')\n",
    "\n",
    "tabela['share_procurement'] = np.where(tabela['sigla_uf']==\"PE\",  \n",
    "                                       tabela['procurement_commitments']/tabela['obs_commitments'],\n",
    "                                       tabela['procurement_commitments']/tabela['distinct_commitments'])\n",
    "\n",
    "tabela['perc_positive_commitments'] = np.where(tabela['sigla_uf']==\"PE\", \n",
    "                                               tabela['total_positive_values']/tabela['obs_commitments'],\n",
    "                                               tabela['total_positive_values']/tabela['distinct_commitments'])\n",
    "\n",
    "tabela_rename = {'distinct_commitments':'Distinct commitments','share_procurement':'Related to procurement',\n",
    "                 'has_verification_information':'Has verification information', \n",
    "                 'has_payment_information':'Has payment information',\n",
    "                 'distinct_verifications':'Distinct verifications', 'distinct_payments':'Distinct payments',\n",
    "                 'total_payment_billion_real':'Total amount of payments', 'distinct_sellers':'Number of distinct sellers',\n",
    "                 'number_municipalities':'Number of distinct municipalities','perc_positive_commitments':'Greater than zero'}\n",
    "\n",
    "tabela.rename(tabela_rename, axis=1, inplace=True)\n",
    "\n",
    "# 3. Totals\n",
    "\n",
    "# stats with information for PE\n",
    "\n",
    "totais = tabela['procurement_commitments'].astype(int).sum()\n",
    "df_totais = pd.DataFrame({'procurement_commitments': [totais]})\n",
    "\n",
    "df_totais['obs_commitments'] = tabela['obs_commitments'].astype(int).sum()\n",
    "df_totais['obs_verifications'] = tabela['obs_verifications'].astype(int).sum()\n",
    "df_totais['obs_payments'] = tabela['obs_payments'].astype(int).sum()\n",
    "\n",
    "df_totais['Number of distinct municipalities'] = tabela['Number of distinct municipalities'].astype(int).sum()\n",
    "\n",
    "df_totais['Total amount of payments'] = tabela['Total amount of payments'].astype(float).sum()\n",
    "\n",
    "# Supose that Distinct commitments and obs_commitments are the same in PE, just to calculate some statistics\n",
    "\n",
    "tabela['Distinct commitments'] = np.where(tabela['sigla_uf']==\"PE\", tabela['obs_commitments'], tabela['Distinct commitments'])\n",
    "\n",
    "df_totais['Related to procurement'] = df_totais['procurement_commitments']/(tabela['Distinct commitments'].astype(int).sum())\n",
    "df_totais['Greater than zero'] = ((tabela['Greater than zero'].astype(float)*tabela['Distinct commitments'].astype(int)).sum())/(tabela['Distinct commitments'].astype(int).sum())\n",
    "\n",
    "tabela['Distinct commitments'] = np.where(tabela['sigla_uf']==\"PE\", np.nan,tabela['Distinct commitments'])\n",
    "\n",
    "# stats without information for PE\n",
    "\n",
    "tabela_sample = tabela[tabela['sigla_uf']!=\"PE\"]\n",
    "\n",
    "df_totais['Distinct commitments'] = tabela_sample['Distinct commitments'].astype(int).sum()\n",
    "\n",
    "df_totais['Has verification information'] = ((tabela_sample['Has verification information'].astype(float)*tabela_sample['Distinct commitments'].astype(int)).sum())/(tabela_sample['Distinct commitments'].astype(int).sum())\n",
    "df_totais['Has payment information'] = ((tabela_sample['Has payment information'].astype(float)*tabela_sample['Distinct commitments'].astype(int)).sum())/(tabela_sample['Distinct commitments'].astype(int).sum())\n",
    "\n",
    "df_totais['Distinct verifications'] = tabela_sample['Distinct verifications'].astype(int).sum()\n",
    "\n",
    "df_totais['Distinct payments'] = tabela_sample['Distinct payments'].astype(int).sum()\n",
    "df_totais['Number of distinct sellers'] = tabela_sample['Number of distinct sellers'].astype(int).sum()\n",
    "df_totais['Number of distinct municipalities'] = tabela_sample['Number of distinct municipalities'].astype(int).sum()\n",
    "\n",
    "tabela = pd.concat([tabela,df_totais],axis=0)\n",
    "tabela['sigla_uf'] = tabela['sigla_uf'].replace(np.nan,'Total')\n",
    "\n",
    "# Rename - as in the paper\n",
    "\n",
    "tabela.rename({'obs_commitments':'Observations commitment',\n",
    "               'Related to procurement':'Related to procurement (%)',\n",
    "               'Greater than zero':'Greater than zero (%)',\n",
    "               'Has verification information':'Has verification information (%)',\n",
    "               'Has payment information':'Has payment information (%)',\n",
    "               'obs_verifications':'Observations verification',\n",
    "               'obs_payments':'Observations payment'},\n",
    "                axis=1, inplace=True)\n",
    "\n",
    "# Format\n",
    "variables_list = ['Related to procurement (%)','Greater than zero (%)',\n",
    "                  'Has verification information (%)','Has payment information (%)']\n",
    "\n",
    "for var in variables_list:\n",
    "    tabela[var] = tabela[var] * 100\n",
    "\n",
    "tabela = tabela.reset_index()\n",
    "tabela.drop('index',axis=1,inplace=True)\n",
    "\n",
    "tabela = tabela.sort_values('sigla_uf')\n",
    "\n",
    "tabela.to_csv(os.path.join(tab_output,'descriptive_statistics_execution.csv'), index=False, na_rep='', float_format='%.1f')\n",
    "\n",
    "tabela_pivo = tabela.transpose()\n",
    "tabela_pivo.columns = tabela_pivo.iloc[0]\n",
    "tabela_pivo = tabela_pivo[1:]\n",
    "tabela_pivo = tabela_pivo.rename_axis(None, axis=1)\n",
    "\n",
    "ordem = ['Observations commitment','Distinct commitments','Related to procurement (%)','Greater than zero (%)',\n",
    "         'Has verification information (%)','Has payment information (%)','Observations verification',\n",
    "         'Distinct verifications','Observations payment','Distinct payments','Total amount of payments',\n",
    "         'Number of distinct sellers','Number of distinct municipalities']\n",
    "\n",
    "tabela_pivo = tabela_pivo.reindex(ordem)\n",
    "\n",
    "# No information for verification \n",
    "tabela_pivo.loc['Distinct verifications', ['CE', 'PB', 'PE']] = None\n",
    "\n",
    "tabela_pivo = tabela_pivo.replace(np.nan, None)\n",
    "\n",
    "# Export TeX table\n",
    "with open(os.path.join(tab_output, 'descriptive_statistics_execution.tex'), 'w') as f:\n",
    "    f.write(tabulate(tabela_pivo, headers='keys', tablefmt='latex_booktabs', floatfmt=(\".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\", \".1f\"),  missingval='-', stralign=\"lrrrrrr\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
